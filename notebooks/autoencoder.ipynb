{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import os.path as pth\n",
    "\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, UpSampling2D, Add, Flatten, Reshape\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, GroupKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "source": [
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = '../data'\n",
    "TRAIN_IMG_DIR = pth.join(ROOT_DIR, 'original/train_images')\n",
    "TRAIN_DATA_DIR = ROOT_DIR\n",
    "\n",
    "WIDTH=1600\n",
    "HEIGHT=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_feather(pth.join(TRAIN_DATA_DIR, 'train.feather'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_groups = data.groupby('imageid')\n",
    "\n",
    "s = image_groups[['mask_present']].sum().mask_present\n",
    "s.name = 'nmasks'\n",
    "data = data.merge(s, left_on=['imageid'], right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(pth.join(TRAIN_DATA_DIR, 'train_masks.pickle.gz'), 'rb') as f:\n",
    "    image_masks = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from loaders import BlockwiseImageLoader\n",
    "n = 4\n",
    "b = BlockwiseImageLoader(train_cv_image_names[0:10], image_groups, image_masks, n, 128, 64)\n",
    "img_patches, mask_patches = b[0]\n",
    "imgs = b.combine_patches(img_patches)\n",
    "\n",
    "for i in range(n):\n",
    "    name = train_cv_image_names[i]\n",
    "    im = plt.imread(pth.join(TRAIN_IMG_DIR, f'{name}.jpg')).astype('float32')[:, :, 0]\n",
    "    plt.figure()\n",
    "    plt.imshow(im, cmap='gray')\n",
    "    plt.show()\n",
    "    plt.figure()\n",
    "    plt.imshow(imgs[i], cmap='gray')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Tensor(\"max_pooling2d_221/MaxPool:0\", shape=(?, 128, 800, 64), dtype=float32) Tensor(\"conv2d_1227/Relu:0\", shape=(?, 256, 1600, 64), dtype=float32)\n",
      "2 Tensor(\"max_pooling2d_222/MaxPool:0\", shape=(?, 64, 400, 128), dtype=float32) Tensor(\"conv2d_1229/Relu:0\", shape=(?, 128, 800, 128), dtype=float32)\n",
      "2 Tensor(\"max_pooling2d_223/MaxPool:0\", shape=(?, 32, 200, 256), dtype=float32) Tensor(\"conv2d_1231/Relu:0\", shape=(?, 64, 400, 256), dtype=float32)\n",
      "2 Tensor(\"max_pooling2d_224/MaxPool:0\", shape=(?, 16, 100, 512), dtype=float32) Tensor(\"conv2d_1233/Relu:0\", shape=(?, 32, 200, 512), dtype=float32)\n",
      "1 Tensor(\"conv2d_1235/Relu:0\", shape=(?, 16, 100, 1024), dtype=float32)\n",
      "Tensor(\"conv2d_1235/Relu:0\", shape=(?, 16, 100, 1024), dtype=float32)\n",
      "Model: \"model_54\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_74 (InputLayer)           [(None, 256, 1600, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1226 (Conv2D)            (None, 256, 1600, 64 640         input_74[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1227 (Conv2D)            (None, 256, 1600, 64 36928       conv2d_1226[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_221 (MaxPooling2D (None, 128, 800, 64) 0           conv2d_1227[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1228 (Conv2D)            (None, 128, 800, 128 73856       max_pooling2d_221[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1229 (Conv2D)            (None, 128, 800, 128 147584      conv2d_1228[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_222 (MaxPooling2D (None, 64, 400, 128) 0           conv2d_1229[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1230 (Conv2D)            (None, 64, 400, 256) 295168      max_pooling2d_222[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1231 (Conv2D)            (None, 64, 400, 256) 590080      conv2d_1230[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_223 (MaxPooling2D (None, 32, 200, 256) 0           conv2d_1231[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1232 (Conv2D)            (None, 32, 200, 512) 1180160     max_pooling2d_223[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1233 (Conv2D)            (None, 32, 200, 512) 2359808     conv2d_1232[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_224 (MaxPooling2D (None, 16, 100, 512) 0           conv2d_1233[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1234 (Conv2D)            (None, 16, 100, 1024 4719616     max_pooling2d_224[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1235 (Conv2D)            (None, 16, 100, 1024 9438208     conv2d_1234[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_565 (UpSampling2D (None, 32, 200, 1024 0           conv2d_1235[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 32, 200, 1536 0           up_sampling2d_565[0][0]          \n",
      "                                                                 conv2d_1233[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1236 (Conv2D)            (None, 32, 200, 512) 7078400     concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1237 (Conv2D)            (None, 32, 200, 512) 2359808     conv2d_1236[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_566 (UpSampling2D (None, 64, 400, 512) 0           conv2d_1237[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 64, 400, 768) 0           up_sampling2d_566[0][0]          \n",
      "                                                                 conv2d_1231[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1238 (Conv2D)            (None, 64, 400, 256) 1769728     concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1239 (Conv2D)            (None, 64, 400, 256) 590080      conv2d_1238[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_567 (UpSampling2D (None, 128, 800, 256 0           conv2d_1239[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 128, 800, 384 0           up_sampling2d_567[0][0]          \n",
      "                                                                 conv2d_1229[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1240 (Conv2D)            (None, 128, 800, 128 442496      concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1241 (Conv2D)            (None, 128, 800, 128 147584      conv2d_1240[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_568 (UpSampling2D (None, 256, 1600, 12 0           conv2d_1241[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 256, 1600, 19 0           up_sampling2d_568[0][0]          \n",
      "                                                                 conv2d_1227[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1242 (Conv2D)            (None, 256, 1600, 64 110656      concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1243 (Conv2D)            (None, 256, 1600, 64 36928       conv2d_1242[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1244 (Conv2D)            (None, 256, 1600, 1) 65          conv2d_1243[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 31,377,793\n",
      "Trainable params: 31,377,793\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from models import SimpleAE, SimpleInception, UNet\n",
    "\n",
    "model = UNet()\n",
    "model.build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = list(data[data.nmasks > 0].imageid.unique())[0:1000]\n",
    "train_cv_image_names, test_image_names = train_test_split(image_names)\n",
    "len(train_cv_image_names), len(test_image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loaders import ImageLoader, BlockwiseImageLoader\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "PATCH_SIZE = 64\n",
    "PATCH_STRIDE = 32\n",
    "\n",
    "kfold = KFold(2)\n",
    "\n",
    "for train_indices, cv_indices in kfold.split(train_cv_image_names):\n",
    "    train_image_names = [train_cv_image_names[i] for i in train_indices]\n",
    "    cv_image_names = [train_cv_image_names[i] for i in cv_indices]\n",
    "    print(f'{len(train_image_names)} training samples, {len(cv_image_names)} validation samples')\n",
    "    model.fit_generator(\n",
    "        generator=ImageLoader(train_image_names, image_groups, image_masks, \n",
    "                              BATCH_SIZE),#, PATCH_SIZE, PATCH_STRIDE),\n",
    "        validation_data=ImageLoader(cv_image_names, image_groups, image_masks, \n",
    "                                    BATCH_SIZE),#, PATCH_SIZE, PATCH_STRIDE),\n",
    "        epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, keys=['loss', 'val_loss']):\n",
    "    if len(keys) == 0:\n",
    "        return\n",
    "    \n",
    "    n = 3\n",
    "    primary = np.array(history[keys[0]])\n",
    "    ymin = primary.mean() - primary.std() * n\n",
    "    ymax = primary.mean() + primary.std() * n\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.ylim(ymin, ymax)\n",
    "    for key in keys:\n",
    "        if key in history.keys():\n",
    "            #plt.plot(np.arange(len(history[key])), history[key], label=key)\n",
    "            plt.plot(history[key], label=key)\n",
    "        else:\n",
    "            print(f'Unable to plot {key}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_history(model.model.history.history)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = test_image_names[0:10]\n",
    "loader = ImageLoader(names, image_groups, image_masks,\n",
    "                     BATCH_SIZE)#, PATCH_SIZE, PATCH_STRIDE)\n",
    "results = model.predict_generator(generator=loader)\n",
    "#results = loader.combine_mask_patches(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, name in enumerate(names):\n",
    "    im = plt.imread(pth.join(TRAIN_IMG_DIR, f'{name}.jpg')).astype('float32')\n",
    "    im /= 255\n",
    "    \n",
    "    print(name)\n",
    "    plt.figure(figsize=(16, 3))\n",
    "    plt.imshow(im, cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "    for j in [1, 2, 3, 4]:\n",
    "        rows = data[(data.imageid == name) & (data.classid == j)]\n",
    "        row = rows.iloc[0, :]\n",
    "\n",
    "        if row.mask_present:\n",
    "            mask_ref = image_masks[f'{name}_{j}']\n",
    "        else:\n",
    "            mask_ref = np.zeros((HEIGHT, WIDTH), dtype='uint8')\n",
    "            \n",
    "        print(name, j, 'REF')\n",
    "        plt.figure(figsize=(16, 3))\n",
    "        plt.imshow(mask_ref, cmap='gray')\n",
    "        plt.show()\n",
    "        \n",
    "        mask_test = results[j - 1][i].squeeze()\n",
    "        #mask_test = (mask_test > 0.5).astype('uint8')\n",
    "        \n",
    "        \n",
    "        print(name, j, 'TEST', np.sum(mask_ref != mask_test))\n",
    "        plt.figure(figsize=(16, 3))\n",
    "        plt.imshow(mask_test, cmap='gray')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
